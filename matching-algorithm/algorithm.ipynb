{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"participant-interests.csv\", index_col=\"kerberosID (S)\")\n",
    "df = df.fillna(0)\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interests = df.iloc[:,:9]\n",
    "df_names = df.iloc[:, 9:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'TF-IDF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_sum_df = df_names.sum()\n",
    "total_sum = sum(individual_sum_df)\n",
    "\n",
    "for index in df_names.index:\n",
    "    for name in df_names.columns:\n",
    "        if index != name.replace(' (S)',''):\n",
    "            df_copy.loc[index, name] *= total_sum/individual_sum_df[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match participant-participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_participants = cosine_similarity(df_copy)\n",
    "cosine_similarity_list = list(cosine_similarity_participants)\n",
    "cosine_similarity_list_copy = cosine_similarity_list.copy()\n",
    "\n",
    "for i in range(len(cosine_similarity_list)):\n",
    "    cosine_similarity_list[i][i] = -1\n",
    "    \n",
    "participants_list = df.index.values.tolist()\n",
    "unmatched_participants = df.index.values.tolist() # initialise all participants as unmatched\n",
    "matched_participants = []\n",
    "pairwise_list = []\n",
    "\n",
    "global cosine_similarity_dict\n",
    "cosine_similarity_dict = {}\n",
    "for i in range(len(cosine_similarity_participants)):\n",
    "    cosine_similarity_dict[unmatched_participants[i]] = list(cosine_similarity_list[i])\n",
    "    \n",
    "cosine_similarity_dict_copy = {}\n",
    "for i in range(len(cosine_similarity_participants)):\n",
    "    cosine_similarity_dict_copy[unmatched_participants[i]] = list(cosine_similarity_list_copy[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pair(index1, index2): \n",
    "    if index1 < index2:\n",
    "        for key, value in cosine_similarity_dict.items():\n",
    "            value.pop(index1)\n",
    "            value.pop(index2 - 1)\n",
    "    else:\n",
    "        for key, value in cosine_similarity_dict.items():\n",
    "            value.pop(index2)\n",
    "            value.pop(index1 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaging_lists(list1, list2):\n",
    "    # average of lists\n",
    "    combined_lists = np.array([np.where(np.asarray(list1) == -1, 0, np.asarray(list1)), np.where(np.asarray(list2) == -1, 0, np.asarray(list2))])\n",
    "    return list(np.average(combined_lists, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(unmatched_participants) > 2:\n",
    "    \n",
    "    # get highest participant\n",
    "    max_participant = max(cosine_similarity_dict, key=cosine_similarity_dict.get) # participant with highest similarity score\n",
    "    max_participant_list = cosine_similarity_dict[max_participant] # highest participant similarity list\n",
    "    \n",
    "    # get best match\n",
    "    match_index = max_participant_list.index(max(max_participant_list)) # index of best match in max_participant_list\n",
    "    match_partcipant = unmatched_participants[match_index] # kerberos of best match\n",
    "    \n",
    "    # append pair\n",
    "    matched_participants.append([max_participant, match_partcipant])\n",
    "    \n",
    "    # add to new df\n",
    "    pairwise_list.append(averaging_lists(cosine_similarity_dict_copy[max_participant], cosine_similarity_dict_copy[match_partcipant]))\n",
    "    \n",
    "    # remove pair\n",
    "    del cosine_similarity_dict[max_participant]\n",
    "    del cosine_similarity_dict[match_partcipant]\n",
    "    \n",
    "    remove_pair(unmatched_participants.index(max_participant), unmatched_participants.index(match_partcipant))\n",
    "    \n",
    "    unmatched_participants.remove(max_participant)\n",
    "    unmatched_participants.remove(match_partcipant)\n",
    "\n",
    "# append final 2\n",
    "matched_participants.append(unmatched_participants)\n",
    "pairwise_list.append(averaging_lists(cosine_similarity_dict_copy[max_participant], cosine_similarity_dict_copy[match_partcipant]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match pair-pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_df = pd.DataFrame(pairwise_list)\n",
    "pairwise_cosine_similarity = cosine_similarity(pairwise_df)\n",
    "\n",
    "pairwise_cosine_similarity_list = list(pairwise_cosine_similarity)\n",
    "                                       \n",
    "pairs_list = matched_participants.copy()\n",
    "unmatched_pairs = matched_participants.copy()\n",
    "                                       \n",
    "global pairwise_cosine_similarity_dict\n",
    "pairwise_cosine_similarity_dict = {}\n",
    "for i in range(len(pairs_list)):\n",
    "    pairwise_cosine_similarity_dict[','.join(unmatched_pairs[i])] = list(pairwise_cosine_similarity_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pairs(index1, index2): \n",
    "    if index1 < index2:\n",
    "        for key, value in pairwise_cosine_similarity_dict.items():\n",
    "            value.pop(index1)\n",
    "            value.pop(index2 - 1)\n",
    "    else:\n",
    "        for key, value in pairwise_cosine_similarity_dict.items():\n",
    "            value.pop(index2)\n",
    "            value.pop(index1 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupings = {}\n",
    "group_number = 1\n",
    "while len(unmatched_pairs) > 2:\n",
    "    \n",
    "    # get lowest pair\n",
    "    min_pair = min(pairwise_cosine_similarity_dict, key=pairwise_cosine_similarity_dict.get) # pair with lowest similarity score\n",
    "    min_pair_list = pairwise_cosine_similarity_dict[min_pair] # lowest pair similarity list\n",
    "\n",
    "    # get worst match\n",
    "    match_pair_index = min_pair_list.index(min(min_pair_list)) # index of worst match in min_pair_list\n",
    "    match_pair = unmatched_pairs[match_pair_index] # kerberos of worst matched pair\n",
    "    \n",
    "    # add pairs\n",
    "    groupings[group_number] = {}\n",
    "    groupings[group_number]['members'] = min_pair.split(\",\") + match_pair\n",
    "\n",
    "    # remove pairs\n",
    "    del pairwise_cosine_similarity_dict[min_pair]\n",
    "    del pairwise_cosine_similarity_dict[','.join(match_pair)]\n",
    "    \n",
    "    remove_pairs(unmatched_pairs.index(min_pair.split(\",\")), unmatched_pairs.index(match_pair))\n",
    "    \n",
    "    unmatched_pairs.remove(min_pair.split(\",\"))\n",
    "    unmatched_pairs.remove(match_pair)\n",
    "    \n",
    "    group_number += 1\n",
    "\n",
    "# add final 2\n",
    "groupings[group_number] = {}\n",
    "groupings[group_number]['members'] = list(np.concatenate(unmatched_pairs).flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top 3 interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in groupings.items():\n",
    "    combined_array = []\n",
    "    for member in value['members']:\n",
    "        combined_array.append(df_interests.loc[member].tolist())\n",
    "    value['interests_values'] = np.average(combined_array, axis=0).tolist()\n",
    "    value['top_interests'] = sorted( [(x,df_interests.columns[i].replace(\" (N)\", \"\")) for (i,x) in enumerate(value['interests_values'])], reverse=True )[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonObject = json.dumps(groupings)\n",
    "jsonFile = open(\"groupings.json\", \"w\")\n",
    "jsonFile.write(jsonObject)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
